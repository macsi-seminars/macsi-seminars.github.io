[
  {
    "objectID": "index.html#seminar-week-1-by-hlib-husarov-eberhard-mayerhofer",
    "href": "index.html#seminar-week-1-by-hlib-husarov-eberhard-mayerhofer",
    "title": "AY 2025-2026 Semester 1 Seminar Schedule",
    "section": "Seminar week 1 by Hlib Husarov & Eberhard Mayerhofer",
    "text": "Seminar week 1 by Hlib Husarov & Eberhard Mayerhofer\nDate: 2025-09-11 at 11am\nSpeaker: Hlib Husarov & Eberhard Mayerhofer (University of Limerick & Mary Immaculate Secondary School, Lisdoonvarna)\nHost: Eberhard Mayerhofer\nTitle: An algorithm for the product-sum equality\nAbstract: We propose a recursive algorithm for identifying all finite sequences of positive integers whose product equals their sum. Our method uses solutions of strictly shorter length that are iteratively extended in pursuit of a valid solution. The algorithm is efficient, with a time complexity similar to the quick sort algorithm. Arxiv: https://arxiv.org/abs/2508.09647"
  },
  {
    "objectID": "index.html#seminar-week-3-by-nico-gray",
    "href": "index.html#seminar-week-3-by-nico-gray",
    "title": "AY 2025-2026 Semester 1 Seminar Schedule",
    "section": "Seminar week 3 by Nico Gray",
    "text": "Seminar week 3 by Nico Gray\nDate: 2025-09-26 at 3pm\nSpeaker: Nico Gray (University of Manchester)\nHost: Andrew Fowler\nTitle: Coupling rheology and segregation in granular flows\nAbstract: During the last fifteen years there has been a paradigm shift in the continuum modelling of granular materials; most notably with the development of rheological models, such as the μ(I)-rheology (where μ is the friction and I is the inertial number), but also with significant advances in theories for particle segregation. This paper details theoretical and numerical frameworks (based on OpenFOAM) which unify these currently disconnected endeavours. Coupling the segregation with the flow, and vice versa, is not only vital for a complete theory of granular materials, but is also beneficial for developing numerical methods to handle evolving free surfaces. This general approach is based on the partially regularized incompressible-rheology, which is coupled to the gravity-driven segregation theory of Gray & Ancey (J. Fluid Mech., vol. 678, 2011, pp. 353-588). These advection-diffusion-segregation equations describe the evolving concentrations of the constituents, which then couple back to the variable viscosity in the incompressible Navier-Stokes equations. A novel feature of this approach is that any number of differently sized phases may be included, which may have disparate frictional properties. Further inclusion of an excess air phase, which segregates away from the granular material, then allows the complex evolution of the free surface to be captured simultaneously. Three primary coupling mechanisms are identified: (i) advection of the particle concentrations by the bulk velocity, (ii) feedback of the particle-size and/or frictional properties on the bulk flow field and (iii) influence of the shear rate, pressure, gravity, particle size and particle-size ratio on the locally evolving segregation and diffusion rates. The numerical method is extensively tested in one-way coupled computations, before the fully coupled model is compared with the discrete element method simulations of Tripathi & Khakhar (Phys. Fluids, vol. 23, 2011, 113302) and used to compute the petal-like segregation pattern that spontaneously develops in a square and triangular rotating drums. Particle-size segregation patterns in a partially filled triangular rotating drum. E.S.F. Maguire, T. Barker, M. Rauter, C.G. Johnson & J.M.N.T. Gray (2024) J. Fluid Mech 979, A40. (movie 1) (movie 2) (movie 3) (movie 4) (movie 5) (movie 6) (movie 7) (movie 8) (movie 9) (movie 10) (movie 11) (movie 12) (movie 13) (movie 14) (movie 15) (movie 16) (movie 17) (movie 18) (movie 19)\nCoupling rheology and segregation in granular flows T. Barker, M. Rauter, E. S. F. Maguire, C. G. Johnson & J. M. N. T. Gray (2021) J. Fluid Mech. 909, A22. (movie 1) (movie 2) (movie 3) (movie 4) (movie 5) (movie 6)\nAn experimental scaling law for particle-size segregation in dense granular flows T. Trewhela, C. Ancey & J. M. N. T. Gray (2021) J. Fluid Mech. 916, A55. (movie 1) (movie 2)\nParticle Segregation in Dense Granular Flows J. M. N. T. Gray (2018) Ann. Rev. Fluid Mech. 50, 407–433. (movies)\nPartial regularisation of the incompressible μ(I)-rheology for granular flow T. Barker & J. M. N. T. Gray (2017) J. Fluid Mech. 828, 5–32. (movies)"
  },
  {
    "objectID": "index.html#seminar-week-10-by-lea-kaufmann",
    "href": "index.html#seminar-week-10-by-lea-kaufmann",
    "title": "AY 2025-2026 Semester 1 Seminar Schedule",
    "section": "Seminar week 10 by Lea Kaufmann",
    "text": "Seminar week 10 by Lea Kaufmann\nDate: 2025-11-13 at 11am\nSpeaker: Lea Kaufmann (RWTH Aachen University)\nHost: Kevin Burke\nTitle: Factor Selection and Levels Fusion in High-Dimensional Logistic Regression\nAbstract: In the last decades, high-dimensional problems in a regression-type context including a large number of explanatory variables arise in a huge variety of application fields. Specifically considering categorical explanatory variables, i.e., factors, the dummy-coding scheme introduces one (dummy) variable for each factor level, thus the dimension of the parameter space grows rapidly, even for a moderate number of factors. To simultaneously obtain the estimates of the regression coefficients and reducing the dimension of the parameter space, penalized regression is known to be a suitable tool. In this talk, I will discuss the characteristics that a penalization technique needs to fulfil to be suitable for the application to factors, as it is not only important to select those having an influence on the response variable (factor selection), but also to fuse those levels of a factor having a similar influence (levels fusion). A new penalization technique, called L0-Fused Group Lasso (L0-FGL), is introduced, tailored for the needs of factors. The quality of this new method is underlined by its theoretical properties, e.g., root-n-consistency and asymptotic normality, as well as by its performance in simulation studies."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-2-by-natalia-kopteva",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-2-by-natalia-kopteva",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 2 by Natalia Kopteva",
    "text": "Seminar week 2 by Natalia Kopteva\nDate: 2025-02-06 at 11am\nSpeaker: Natalia Kopteva (University of Limerick)\nHost: NA\nTitle: Fractional differential equations: gentle introduction and gentle numerical analysis\nAbstract: Over the past decade, there has been a growing interest in evolution equations of parabolic type that involve fractional-order derivatives in time of order in (0, 1). Such equations, also called subdiffusion equations, arise in various applications in engineering, physics, biology and finance. Hence, it is quite important to develop efficient and reliable computational tools for their numerical solution.\nIn this talk, I will touch on similarities and differences between fractional-parabolic equations and their classical counterparts, including the non-local nature of fractional-order derivatives, initial-time solution singularities, and slower long-term solution decay, as well as the proofs of some regularity properties and maximum principles. Then we shall consider some robust numerical methods for such equations, as well as the derivation of a-priori and a-posteriori estimates of the computational errors.\nCompared to my recent talks on this topic (which some in the audience may have attended), I plan to give more focus to the numerical solution of such equations, as well as some basic ideas in their numerical analysis."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-4-by-davood-roshan",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-4-by-davood-roshan",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 4 by Davood Roshan",
    "text": "Seminar week 4 by Davood Roshan\nDate: 2025-02-20 at 11am\nSpeaker: Davood Roshan (University of Galway)\nHost: Shirin Moghaddam\nTitle: Challenge Your Limits!\nAbstract: Interval estimation is a cornerstone of statistical inference. Regardless of whether an interval has been derived using a frequentist, Bayesian or computational approach the ‘practical’ interpretation is the same, a set of values ’likely’ to contain the parameter of interest. Interval estimation in introductory statistics courses often involves frequentist approaches for one/two sample problems. A common misuse, particularly when comparing two treatments, is when a Confidence Interval is used instead of a Prediction Interval in estimating the likely improvement for a future individual receiving the treatment of interest. Prediction Intervals however are typically introduced later in the curriculum as a component of simple linear regression. Other solution to consider is to report Tolerance Intervals which aims to provide a range of values for the treatment effect for a certain percent of the population of interest. Despite their appeal, Tolerance Intervals are rarely included in introductory courses. They may feature in some medical statistics courses as population-based reference intervals to interpret a set of laboratory test results for a particular individual. In this presentation, a review and discussion of the use and misuse of confidence, prediction, and tolerance intervals and their place in the curriculum will be discussed. New approaches for generating personalised adaptive reference intervals for longitudinal monitoring will be also presented. Such adaptive reference intervals will adapt successively whenever a new measurement is recorded for an individual by accounting for both the between and within individual variability."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-6-by-mainendra-dewangan",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-6-by-mainendra-dewangan",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 6 by Mainendra Dewangan",
    "text": "Seminar week 6 by Mainendra Dewangan\nDate: 2025-03-06 at 11am\nSpeaker: Mainendra Dewangan (University of Limerick)\nHost: Mehakpreet Singh\nTitle: Effects of Topographical Wall Patterns on Flow through Porous Media\nAbstract: The Darcy-Brinkmann (DB) model advances the understanding of fluid flow through a porous medium by extending the foundational principles of Darcy’s law to include viscous shear effects. This enhancement is crucial for accurately analyzing flows that are significantly influenced by both the porous characteristics and the viscous shear (Brinkmann effect). Integration of these effects makes the DB model a more comprehensive tool for studying complex flow dynamics. Exploring fluid flow in porous media is essential for designing and optimizing various engineering systems, including filtration devices, chemical reactors, and technologies for cooling microelectronics. With this motivation, the present study investigates the flow characteristics of a viscous, incompressible, steady, and Newtonian fluid through an undulating microchannel containing a porous medium. The flow is governed by the Darcy–Brinkman model with no-slip boundary conditions at walls. The primary objective of this study is to develop theoretical and computational models for flow parameters that are independent of the permeability of porous medium and to extend the scope of previous studies. Lubrication theory is employed to analyze key flow parameters such as flow rate, velocity, and wall shear stress in complex-shaped microchannels. However, the spectral method is applied to a sinusoidal microchannel to overcome the limitations of lubrication and boundary perturbation methods. The present study reveals that flow parameters are significantly influenced by dimensionless quantities such as pattern amplitude, wavelength, and permeability (κ). The spectral model predicts nonlinear flow rate behaviour at high permeability (κ ≫ 1 ) and accurately captures flow rate transitions in the Darcian flow regime across various wavelengths, unlike other theoretical approaches. Conversely, for low permeability (κ ≪ 1) in the Stokes flow limit, the flow rate behaviour remains monotonic for both small and large wavelengths. The spectral model exhibits good reliability compared to classical lubrication theory, extended lubrication theory, and boundary perturbation methods, particularly for large values of dependent variables. Predictions from the spectral approach show good agreement with numerical results across a broad range of parameters. A detailed analysis of the influence of various parameters on flow quantities is examined. The findings of the present study are highly significant and have broad applications in multiple fields, such as chemical reactors, filtering equipment, heat exchangers, and flow through rock fractures."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-8-by-iain-moyles",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-8-by-iain-moyles",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 8 by Iain Moyles",
    "text": "Seminar week 8 by Iain Moyles\nDate: 2025-03-19 at 2pm\nSpeaker: Iain Moyles (York University)\nHost: Andrew Fowler\nTitle: The Only Thing to Fear is Fear Itself\nAbstract: We present a disease model with behavioural impact in the form of fear of infection. This fear induces prophylactic action in the form of contact reduction. Increase in fear is driven by rising case numbers while decrease in fear occurs both naturally over time and with increasing recovery of infection. We show that our model exhibits two limits, one where fear can be effective at mitigating the disease and one where it is not. When fear is an effective tool, we analyze its limitations in stopping disease spread."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-10-by-robert-garvey",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-10-by-robert-garvey",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 10 by Robert Garvey",
    "text": "Seminar week 10 by Robert Garvey\nDate: 2025-04-03 at 11am\nSpeaker: Robert Garvey (University of Limerick)\nHost: Michael Vynnycky\nTitle: Hydrodynamics and drug dissolution in USP4\nAbstract: The dissolution of solid spherical particles is a canonical problem found in many applications. Of particular interest is the dissolution of drug particles in the pharmaceutical industry. In-vitro dissolution testing is crucial in investigating drug quality, stability, and regulatory compliance. The United States Pharmacopoeia set guidelines for testing dissolution and outlines seven main testing apparatus. One such widely utilised apparatus is the flow through device, USP4. The USP4 apparatus comprises of three main components: a reservoir containing the dissolution medium; a pump responsible for controlling the flow rate of the fluid; and a flow-through cell where the drug sample is situated as dissolution occurs.\nThe solvent fluid is ordinarily pumped in a semi-sinusoidal manner or at a constant flow rate. This flow rate is impactful on dissolution characteristics. Mathematical modelling may be utilised to understand the complex interaction between the hydrodynamics and the dissolution process within the USP4 system. We investigate existing models; such models are solved numerically. We use non-dimensionalisation and asymptotic methods to derive analytical asymptotic solutions to these existing model equations. Our analytics are compared with numerical results and found to give good agreement; such analytical solutions are particularly valuable due to the time-consuming nature of solving these equations numerically, owing directly to the presence of the Basset history integral force. This Basset history integral may be interpreted as a fractional derivative.\nExisting models are unable to accurately capture all experimental data. We discuss recent developments on the modelling of hydrodynamics and dissolution and outline potential improvements."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-10-by-colm-mulcahy",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-10-by-colm-mulcahy",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 10 by Colm Mulcahy",
    "text": "Seminar week 10 by Colm Mulcahy\nDate: 2025-04-04 at 11am\nSpeaker: Colm Mulcahy (Spelman College)\nHost: Romina Guborro\nTitle: One, Two, Many (or a dozen reasons why mathematics isn’t as easy as 1,2,3)\nAbstract: Are there really primitive tribes whose system of counting goes: “One, Two, Many”, indicating that\nfrom three on it’s more or less a blur? Maybe we modern humans are such a tribe. Despite the\nsophistication we see in ourselves compared with our less advanced ancestors from times long past,\nit’s surprising how little progress we’ve made in addressing some basic problems in 3D or beyond, or\nwhen solving seemingly simple equations in 3 or more variables. For despite our astonishing mastery\nof some ABCs, such as Air (flight, weather prediction), Biology (medical breakthroughs, DNA) and\nCommunications (phone, video, email), we often struggle to get past 1, 2, 3 in other domains. Or\nsometimes even to get to 3. We’ll survey a dozen fun topics in shapes and numbers and patterns\nwhose basics and generalization can be explored with little mathematical background, and which\nspeedily lead to “what if” questions ranging from easy to tricky to “we just don’t know.” Coins, cakes,\nfruit, bagels, cubes, squares and primes will all make an appearance. The late Martin Gardner, whose writings turned so many on to maths, knew all too well that such playful queries\ncan both excite students about mathematics and lead to real research at the frontiers of the subject.\nThere will be satisfying Aha! moments, there will be room for innovative ideas, and million dollar\nprizes will be discussed."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-11-by-colm-connaughton",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-11-by-colm-connaughton",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 11 by Colm Connaughton",
    "text": "Seminar week 11 by Colm Connaughton\nDate: 2025-04-10 at 11am\nSpeaker: Colm Connaughton (London Mathematical Laboratory)\nHost: Padraig MacCarron\nTitle: Rationality, decision theory and ergodicity\nAbstract: In decision theory, choice in the presence of uncertainty - think of deciding whether or not to place a bet on a horse - is typically modelled as a process of expected utility maximisation. Agents are assumed to possess an intrinsic  utility function that ascribes a “value” to each possible outcome. An uncertain choice is then considered rational if it maximises the expected utility of the set of possible outcomes. In this talk, I will describe some examples of repeated gambles which illustrate some inconsistencies with this notion of rationality. For additive, gambles, where the potential payoffs are independent of an agent’s current wealth, all seems to work fine. In contrast, for multiplicative gambles, where payoffs are proportional to an agent’s current wealth, one encounters situations in which the expected utility grows exponentially with the number of rounds played while the typical wealth goes to zero with probability one. The mathematical root of the problem lies in the interchangeability (or not) of the ensemble  average outcome and the time average outcome - what physicists refer to as ergodicity. The evolution of an agent’s wealth during a sequence of additive gambles can be modelled as a simple random walk which has ergodic increments. A sequence of multiplicative gambles, however, should be modelled as a geometric random walk whose increments strongly break ergodicity. The failure to properly account for this distinction can explain many so-called irrationalities in decision theory and behavioural economics. If time allows, I will also describe some more technical work constructing a stochastic process that interpolates smoothly between the additive and multiplicative random walks. The aim is to better understand the nature of the ergodicity breaking observed in the multiplicative case."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-11-by-sarah-heaps",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-11-by-sarah-heaps",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 11 by Sarah Heaps",
    "text": "Seminar week 11 by Sarah Heaps\nDate: 2025-04-11 at 12pm\nSpeaker: Sarah Heaps (Durham University)\nHost: James Sweeney\nTitle: Bayesian inference of sparsity in stationary, multivariate autoregressive processes\nAbstract: In many fields, advances in sensing technology have made it possible to collect large volumes of time-series data on many variables. In a diverse array of fields such as finance, genetics and neuroscience, a key question is whether such data can be used to learn directed relationships between variables. In other words, do changes in one variable consistently precede those in another? Graphical vector autoregressions are a popular tool for characterising directed relationships in multivariate systems because zeros in the autoregressive coefficient matrices have a natural graphical interpretation in terms of the implied Granger (non)-causality structure. In many applications, it is natural to assume that the underlying process is stable so that, for example, uncertainty in forecasts does not increase without bound as the forecast horizon increases. Though stationarity is commonly stated as an assumption, it is generally not enforced as a constraint because enforcing stability demands restricting the autoregressive coefficient matrices to lie in a constrained space, with a complex geometry, called the stationary region. This is problematic because the number parameters grow quadratically with dimension, making it increasingly difficult to learn, with certainty, that a process is stationary. Working in the Bayesian paradigm, we use a parameter expansion approach to tackle the problem of inference for sparse and stable vector autoregressions by constructing a spike-and-slab prior with support constrained to the stationary region. Computational inference is carried out via a Metropolis-within-Gibbs scheme which uses Hamiltonian Monte Carlo to draw from the full conditional distribution of the continuous parameters. To illustrate our approach, we consider long-term spatio-temporal data on interictal epileptic activity (IEA), which are abnormal brain activity patterns mostly seen in people with epilepsy. Learning about the drivers of variability in this application has the potential to transform epilepsy treatment as the IEA rate is thought to underpin the cognitive deficits in this cohort."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-12-by-edward-gunning",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-12-by-edward-gunning",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 12 by Edward Gunning",
    "text": "Seminar week 12 by Edward Gunning\nDate: 2025-04-17 at 11am\nSpeaker: Edward Gunning (University of Pennsylvania)\nHost: Norma Bargary\nTitle: Non-linear Latent Representations in Functional Data Modeling\nAbstract: Latent feature representations (e.g., PCA) are widely used for dimensionality reduction and statistical modeling of high-dimensional functional and multivariate data. Traditional functional regression models typically rely on linear basis expansions (e.g., PCA, B-splines, wavelets), but modern non-linear machine learning methods (e.g., autoencoders, GANs) offer more flexible alternatives. In this work, we present two main contributions: 1. We propose CLaRe (Compact near-Lossless Latent Representations), a flexible evaluation framework for selecting among linear and non-linear latent feature representations in high-dimensional functional and multivariate data. CLaRe provides a principled set of criteria to assess methods based on their dimensionality reduction (compactness) and the information they preserve (near-losslessness). 2. We demonstrate how, when non-linear methods such as autoencoders are selected, they can be embedded within the Functional Mixed Model (FMM) framework of Morris and Carroll (2006). This integration enables flexible modeling of complex functional structures while retaining the interpretability and inference capabilities of FMMs. We illustrate the utility of this approach on multidimensional functional imaging data."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-13-by-leonard-henckel",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-13-by-leonard-henckel",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 13 by Leonard Henckel",
    "text": "Seminar week 13 by Leonard Henckel\nDate: 2025-04-24 at 11am\nSpeaker: Leonard Henckel (University College Dublin)\nHost: Kevin Burke\nTitle: Graphical tools for selecting conditional instrumental sets\nAbstract: Causal inference studies how to use statistical tools to infer the properties of an unobserved distribution corresponding to a hypothetical experiment from observational data. A popular tool for causal inference are instrumental variables; auxiliary variables that affect the treatment in a way that mimics an experiment. However, it is also well-known that instrumental variable estimators tend to be inaccurate and that their accuracy heavily depends on the choice of instrument. We consider the problem of how to characterize which auxiliary variables result in efficient estimators under the assumption that we are given approximate knowledge of the underlying causal structure in the form of a causal graph. We first characterize the class of all valid conditional instrumental sets for the target causal effect and provide a graphical criterion that, for certain pairs, identifies which of the two corresponding estimators has the smaller asymptotic variance. We then use these two results to characterize a valid conditional instrumental set for which the corresponding estimator has the smallest asymptotic variance that can be ensured with a graphical criterion."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-15-by-miriam-casey",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-15-by-miriam-casey",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 15 by Miriam Casey",
    "text": "Seminar week 15 by Miriam Casey\nDate: 2025-05-08 at 11am\nSpeaker: Miriam Casey (University College Dublin)\nHost: David O’Sullivan\nTitle: Application of mathematical modelling to infectious animal disease challenges\nAbstract: Inferring hidden infectious disease processes through integration of quantitative, biological, and socioeconomic expertise can inform policy for effective disease control. I will present snapshots of my previous interdisciplinary research into foot-and-mouth disease and Covid-19 and its subsequent impacts. The focus of the presentation will be my current work applying a similar approach to bovine tuberculosis in Ireland. In Ireland, Mycobacterium bovis is the most prevalent of the zoonotic Mycobacterium tuberculosis complex bacteria in animals, and causes bovine tuberculosis (bTB) in cattle. The bTB control programme cost approximately €2 billion between 2013 and 2023, and increasing levels of bTB threaten our cattle product export market access which, in 2022, was worth approximately €9.45 billion. Uncertainties relating to complex multi-species epidemiology of bTB, highly imperfect diagnostic testing, in association with robust stakeholder debate about cattle and wildlife related control measures, create disease control challenges. Through fitting a stochastic mechanistic model to bTB breakdown data in 9,137 Irish cattle herds, we aimed to improve our understanding of M. bovis transmission within herds, to estimate where in the diagnostic testing process infected cattle are being missed, and to enable exploration of the potential impact of interventions. The current best-fit model uses the susceptible-occult-reactive compartmental framework, animal level heterogeneity in transmission, and allows for reduced test sensitivity prior to initial case diagnosis in each herd-level skin test event. This framework, using parameters inferred by Approximate Bayesian Computation (ABC), produces simulations with an acceptable fit to 23 target metrics in the data. I will present our results, including new evidence about mechanisms relating to M. bovis transmission and diagnosis. I will also describe the computational and statistical challenges and opportunities highlighted by the project and future research plans."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-17-by-jacob-curran-sebastian",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-17-by-jacob-curran-sebastian",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 17 by Jacob Curran-Sebastian",
    "text": "Seminar week 17 by Jacob Curran-Sebastian\nDate: 2025-05-22 at 2pm\nSpeaker: Jacob Curran-Sebastian (University of Copenhagen)\nHost: James Gleeson\nTitle: Modeling the importation and transmission dynamics of a novel pathogenic strain using branching processes.\nAbstract: The importation and subsequent establishment of novel pathogenic strains in a population is subject to a large degree of uncertainty due to the stochastic nature of the disease dynamics. Mathematical models need to take this stochasticity in the early phase of an outbreak in order to adequately capture the uncertainty in disease forecasts. We start with a simple branching process model of disease spread, which we then build upon to include within-host level heterogeneity and a time-varying transmission rate. This flexible approach can be straightforwardly tailored to capture the salient aspects of a disease outbreak. We combine this with a model of case importation that occurs via an independent marked Poisson process.\nWe use this framework to investigate the impact of different control strategies, particularly on the time to establishment of an invading, exogenous strain. We also demonstrate the relationship between our model and deterministic approximations, such that longer term projections can be generated that still incorporate the uncertainty from the early growth phase of the epidemic. Our approach produces meaningful projections for a disease outbreak that are applicable in a wide variety of settings. These can be used by policymakers, for example, to estimate the length time for which interventions need to be in place in order to achieve either local elimination of a disease or a delay in the time at which the disease becomes established in the population."
  },
  {
    "objectID": "create_AY24-25_sem_2_timetable.html#seminar-week-18-by-jean-gabriel-young",
    "href": "create_AY24-25_sem_2_timetable.html#seminar-week-18-by-jean-gabriel-young",
    "title": "AY 2024-2025 Semester 2 Seminar Schedule",
    "section": "Seminar week 18 by Jean-Gabriel Young",
    "text": "Seminar week 18 by Jean-Gabriel Young\nDate: 2025-05-28 at 12pm\nSpeaker: Jean-Gabriel Young (University of Vermont)\nHost: David O’Sullivan\nTitle: Designing interventions with message passing on clustered graphs\nAbstract: Models of contagions can describe many network dynamics, such as cascading failures in economic systems, information diffusion, and pathogen transmission. They figure prominently in intervention design problems—for example, deciding how to roll out vaccines or designing robust economic systems. The idea is, roughly, to test counterfactuals provided by realistic contagion models and tune the system to increase the likelihood of favorable outcomes. Unfortunately, this process involves costly numerical optimization and calculations. In this talk, I will first review the message passing framework, which is routinely used to tame the intervention design problem’s complexity. I will then highlight some well-known issues with this framework, chiefly that it overestimates the likelihood of a contagion spreading. I will then discuss two promising approaches for correcting this issue: the neighborhood message passing (NMP) framework and a new graph machine learning algorithm."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-0-by-marcos-prates",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-0-by-marcos-prates",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 0 by Marcos Prates",
    "text": "Seminar week 0 by Marcos Prates\nDate: 2024-01-26 at 12pm\nSpeaker: Marcos Prates (NA)\nHost: James Sweeney\nTitle: Spatial Confounding Beyond Generalized Linear Mixed Models: Extension to Shared Components and Spatial Frailty Models\nAbstract: Spatial confounding is defined as the confounding between the fixed and spatial random effects in generalized linear mixed models (GLMMs). It gained attention in the past years, as it may generate unexpected results in modeling. We introduce solutions to alleviate the spatial confounding beyond GLMMs for two families of statistical models. In the shared component models, multiple count responses are recorded at each spatial location, which may exhibit similar spatial patterns. Therefore, the spatial effect terms may be shared between the outcomes in addition to specific spatial patterns. Our proposal relies on the use of modified spatial structures for each shared component and specific effects. Spatial frailty models can incorporate spatially structured effects and it is common to observe more than one sample unit per area which means that the support of fixed and spatial effects differs. Thus, we introduce a projection-based approach for reducing the dimension of the data. An R package named “RASCO: An R package to Alleviate Spatial Confounding” is provided. Cases of lung and bronchus cancer in the state of California are investigated under both methodologies and the results prove the efficiency of the proposed methodology."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-1-by-emmanuil-h.-georgoulis",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-1-by-emmanuil-h.-georgoulis",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 1 by Emmanuil H. Georgoulis",
    "text": "Seminar week 1 by Emmanuil H. Georgoulis\nDate: 2024-02-01 at 12pm\nSpeaker: Emmanuil H. Georgoulis (NA)\nHost: Natalia Kopteva\nTitle: Hypocoercivity-preserving Galerkin discretisations of kinetic equations\nAbstract: Numerous physical, chemical, biological, and social dynamic processes are characterised by convergence to long-time equilibria. These are often described as PDEs of kinetic type, whereby position'' andvelocity’’ are independent variables; well known examples of such are Kolmogorov and Fokker-Planck equations. These may also arise when modelling multi-agent interacting processes of particles, individuals, etc. In many important cases the diffusion/dissipation required to arrive to such equilibria is explicitly present in some of the spatial directions only, that is there exist evolution PDEs with degenerate diffusion yet converging to equilibrium states as time goes to infinity. This, somewhat counter-intuitive at first, state of affairs suggests that decay to equilibrium is due to finer hidden structure, which allows for the transport terms to also “propagate dissipation” to the spatial directions in which no dissipation appears explicitly in the PDE model. This property has been studied extensively by Villani who coined the term “hypocoercivity” to describe it in his celebrated 2009 AMS Memoir.\nIn the talk I will present recent results on how to design and analyse hypocoercivity-preserving Galerkin discretisations, in an effort to port the concept of hypocoercivity in the design and analysis of cutting-edge numerical methods. To that end I plan to start by presenting the first provably hypocoercivity-preserving Galerkin (non-conforming) finite element method for the model problem of Kolmogorov equation and discuss some very recent results on a different approach for the same equation. I plan to conclude with some first results of Galerkin methods for the inhomogeneous Fokker-Plack equation on exponentially weighted function spaces. Some of the results are joint work with Zhaonan Dong (INRIA, Paris) and Philip Herbert (Sussex)."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-1-by-william-lee",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-1-by-william-lee",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 1 by William Lee",
    "text": "Seminar week 1 by William Lee\nDate: 2024-02-02 at 12pm\nSpeaker: William Lee (NA)\nHost: Kevin Moroney\nTitle: Nonuniform flow in coffee extraction\nAbstract: Coffee is a drink made by dissolving the soluble parts of ground, roast coffee beans in water. In espresso coffee this is done at high temperatures and pressures. It seems obvious that grinding coffee more finely will lead to more coffee being extracted. However, a recent experiment showed that, beyond a cutoff point grinding coffee more finely results in lower extraction. One possible explanation for this is that fine grinding promotes uneven extraction in the coffee bed. To explore this a low dimensional model in which there are two possible pathways for flow and coffee extraction is derived and analysed. This model shows that, below a critical grind size, there is decreasing extraction with decreasing grind size as is seen experimentally. In the model this is due to a complicated interplay between an initial imbalance in the porosities and permeabilities of the two pathways which is increased by flow and extraction, leading to the complete extraction of all soluble coffee from one pathway."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-2-by-cameron-hall",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-2-by-cameron-hall",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 2 by Cameron Hall",
    "text": "Seminar week 2 by Cameron Hall\nDate: 2024-02-09 at 12pm\nSpeaker: Cameron Hall (NA)\nHost: Kevin Moroney\nTitle: Opportunities and challenges in optimising power grid stability\nAbstract: Decarbonising electricity generation is essential to any attempt to achieve net zero carbon dioxide emissions. However, the move to variable renewable energy sources such as wind turbines and solar photovoltaics creates new challenges for ensuring the stability of power grids. A major reason for this is that variable renewable energy sources often have very low inherent inertia. Inertia in this context is a measure of the tendency of the grid to maintain its frequency, even when imbalances between power supply and power demand create a push for the frequency to change. Since power grids can only be stable when power frequency is maintained within a very narrow range, the low inertia of variable renewable energy sources tends to destabilise the power grid, leading to possible grid failures.\nOne key tool for ensuring grid stability is mathematical modelling. Models of power grids can be used to estimate the inherent stability of the system, and models can be used to optimise the controllable features of generators to help ensure grid stability. Recent sophisticated optimisation methods have been proposed for finding optimal generator parameters for power grids. In this talk, I will describe some of these optimisation methods and explore some of their strengths and weaknesses. In particular, I will look at how robust the optimisation methods are when certain model parameters are not known exactly, or when multiple generators are combined in a model and treated as a single generator."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-3-by-srikanth-toppaladoddi",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-3-by-srikanth-toppaladoddi",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 3 by Srikanth Toppaladoddi",
    "text": "Seminar week 3 by Srikanth Toppaladoddi\nDate: 2024-02-16 at 12pm\nSpeaker: Srikanth Toppaladoddi (NA)\nHost: Anthony Bonfils\nTitle: Brownian Motion, Polar Oceans, and the Statistical Physics of Climate\nAbstract: In this talk, I will show how tools from statistical physics can be used to study the Earth’s climate. The specific problem addressed is the geophysical-scale evolution of Arctic sea ice. Using an analogy with Brownian motion, the original evolution equation for the sea ice thickness distribution function, g(h), by Thorndike et al. (J. Geophys. Res. 80(33), 4501(1975)) is transformed to a Fokker-Planck-like equation. The steady solution for wintertime is g(h) = N(q, H) * h^q * exp(-h/H), where q and H are expressible in terms of moments over the transition probabilities between thickness categories. This solution exhibits the functional form used in observational fits and shows that for h &lt;&lt; 1, g(h) is controlled by both thermodynamics and mechanics, whereas for h &gt;&gt; 1 only mechanics controls g(h). Furthermore, seasonality is introduced by using the Eisenman-Wettlaufer (Proc. Natl. Acad. Sci. USA 106, 28 (2009)) and Semtner (J. Phys. Oceanogr. 6, 379 (1976)) models for the thermal growth of sea ice. The time-dependent problem is studied by numerically integrating the Fokker-Planck equation. The results obtained from these numerical integrations and their comparison with submarine and satellite observations of ice thickness will also be discussed."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-4-by-maeve-upton",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-4-by-maeve-upton",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 4 by Maeve Upton",
    "text": "Seminar week 4 by Maeve Upton\nDate: 2024-02-23 at 12pm\nSpeaker: Maeve Upton (NA)\nHost: James Sweeney\nTitle: Bayesian generalised additive models for quantifying sea-level change.\nAbstract: The 2021 Intergovernmental Panel on Climate Change report highlighted how rates of sea level rise are the fastest in at least the last 3,000 years. As a result, understanding historical sea level trends globally and locally is important to comprehend the dynamics and impacts of sea level change. The influence of different sea level drivers, for example thermal expansion, ocean dynamics and glacial – isostatic adjustment (GIA), has changed throughout time and space. Therefore, a useful statistical model requires both flexibility in time and space and have the capability to examine these separate drivers, whilst taking account of uncertainty.\nIn this talk, I will discuss the statistical models we developed to examine historic relative sea level changes, employing sea-level proxy and tide gauge data and the noisy input uncertainty method to account for uncertainty. Our approach uses Generalised Additive Models (GAMs) within a Bayesian framework which enables separate modelling of sea level components, smooth calculation of rates and the ability to incorporate external prior information guiding the evolution of sea level change over time and space. Our findings reveal that current sea levels along North America’s Atlantic coast are the highest in at least the past 15 centuries. GAMs demonstrate the different drivers of relative sea level change, indicating that GIA dominated until the 20th century when a sharp rise in sea level change rates occurred."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-6-by-ben-taylor",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-6-by-ben-taylor",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 6 by Ben Taylor",
    "text": "Seminar week 6 by Ben Taylor\nDate: 2024-03-08 at 12pm\nSpeaker: Ben Taylor (NA)\nHost: James Sweeney\nTitle: Modelling and inference for Spatial Processes Under Aggregation and Change of Support\nAbstract: The issues of aggregation and change of support are common in practical applications involving space-time data. They arise when the true process is continuous in space-time, but only data from different aggregation units, e.g. point-locations, or administrative regions, are available. The challenges posed by such data are often ignored, or substantially simplified in practice. In this talk, I will introduce two strands of research concerning the modelling of spatial/spatiotemporal data measured across multiple types of support, one concerning the modelling of spatiotemporal point process data on malaria in Zambia and a second concerning geostatistical modelling of land suitability in Wales."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-7-by-michael-fop",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-7-by-michael-fop",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 7 by Michael Fop",
    "text": "Seminar week 7 by Michael Fop\nDate: 2024-03-15 at 12pm\nSpeaker: Michael Fop (NA)\nHost: Shirin Moghaddam\nTitle: Model-based clustering of networks with compositional edges\nAbstract: Networks represent complex systems that capture interactions among entities, often resulting in the formation of communities. Additionally, networks frequently depict flows of quantities between nodes. For instance, in the Erasmus programme exchange network, interactions between European countries correspond to volumes of students being transferred among them. When modeling such networks, the exchanged volumes are influenced by the nodes’ capacities to send and receive quantities, which can vary significantly across the network and may be associated with uninteresting aspects of the data. In the Erasmus programme network, for example, the volume of outgoing students from a country is limited by the size of its student population. Similarly, the volume of incoming students to a country is associated with the number of universities, which is also related to its student population. Clustering nodes in such networks by directly modeling these volumes often results in clustering solutions that merely reflect the capacities of sending and receiving nodes, masking interesting patterns associated with the relative strength of the connecting flows. We propose a model-based clustering approach that utilizes the relative strength of connections, leveraging concepts from compositional data analysis. We introduce a novel Dirichlet stochastic block model for clustering nodes in networks with compositional edge weights. The model relies on a mixture of Dirichlet distributions, whose parameters are determined by the cluster allocations of sender and receiver nodes, allowing for different propensities for retaining or transferring quantities over the network between the clusters. Consequently, nodes are clustered based on flows as parts of a whole, rather than raw volumes. Inference is implemented using a variation of the classification expectation-maximization algorithm, enabling efficient computations. The model is tested in a number of synthetic data experiments, showing good performance. Furthermore, we showcase the model on two datasets: the Erasmus programme exchange network among European countries and a bike-sharing network for the city of London."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-9-by-graham-benham",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-9-by-graham-benham",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 9 by Graham Benham",
    "text": "Seminar week 9 by Graham Benham\nDate: 2024-03-28 at 12pm\nSpeaker: Graham Benham (NA)\nHost: Doireann O’Kiely\nTitle: Wave-driven propulsion\nAbstract: Wave-driven propulsion occurs when a floating body, driven into oscillations at the fluid interface, is propelled by the waves generated by its own motion. Wave-driven propulsion has been observed in the case of the waves generated by a honeybee trapped on the surface of water, in the case of “SurferBot”, a centimeter-scale interfacial robot that was inspired by the stricken honeybee, and at much larger scales, in the case of the waves generated by jumping up and down on a canoe, also known as “gunwale bobbing”.\nIn this seminar I will present a new theory for wave-driven propulsion based on coupling the equations of motion of a floating raft to a quasi-potential flow model of the fluid. Using this model, expressions are derived for the drift speed and propulsive thrust of the raft which in turn are shown to be consistent with global momentum conservation. The validity of the model is explored by describing the motion of SurferBot, demonstrating close agreement with the experimentally determined drift speed and oscillatory dynamics. The efficiency of wave-driven propulsion is then computed as a function of driving oscillation frequency and the forcing location, revealing optimal values for both of these parameters which await confirmation in experiments."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-10-by-dan-giles",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-10-by-dan-giles",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 10 by Dan Giles",
    "text": "Seminar week 10 by Dan Giles\nDate: 2024-04-04 at 12pm\nSpeaker: Dan Giles (NA)\nHost: James Gleeson\nTitle: Embedding sub-grid variability into hybrid climate simulations to improve convective modelling\nAbstract: Atmospheric General Circulation Models (AGCMs) play a vital role in our understanding of climate dynamics and how the climate is changing. However, carrying out climate projections using the latest AGCMs is a computationally expensive task due to long integration timescales and the need to explore the impact of different forcing pathways. As a result, climate simulations are typically carried out using spatial resolutions on the order of 100km. This coarse spatial resolution leads to biases associated with cloud formation, convection, precipitation and interactions between the water cycle and the large-scale dynamics.\nThis work aims to tackle these biases associated with convective scale processes by embedding a multi-output Gaussian Process (MOGP), trained to predict high resolution variability of temperature and specific humidity fields, within the AGCM. A proof-of-concept study will be presented where a trained MOGP model is coupled in-situ with a simplified AGCM. The temperature and specific humidity profiles of the AGCM model outputs are perturbed at fixed time intervals according to the predicted high resolution informed variability. Modelling improvements in the precipitation, outgoing longwave and shortwave radiation patterns are observed in a 10-year simulation run and the physical justifications for these changes will be explored. This work showcases a promising approach towards improving the overall representation of sub-grid cell processes in coarse resolution atmospheric simulations."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-10-by-kieran-mulchrone",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-10-by-kieran-mulchrone",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 10 by Kieran Mulchrone",
    "text": "Seminar week 10 by Kieran Mulchrone\nDate: 2024-04-05 at 12pm\nSpeaker: Kieran Mulchrone (NA)\nHost: David O’Sullivan\nTitle: Rate-Induced Tipping of the Compost Bomb: Sizzling Summers, Heteroclinic Canards and Metastable Zombie Fires\nAbstract: The Arctic is the fastest warming region on Earth. Understanding how a rapidly changing climate change impacts Arctic systems is therefore an important challenge. This is the basis of the `Compost-Bomb’ instability, a theorized runaway heating of northern latitude peat soils when atmospheric temperature rises faster than some critical rate, first proposed in [Luke & Cox, European Journal of Soil Science (2011), 62.1] and analysed in [Wieczorek et al, Proceedings of the Royal Society A (2011), 467.2129]. The Compost Bomb instability was one of the first examples of what is known as Rate-induced tipping or R-tipping.The key trigger for the compost bomb instability is heat produced by microbial respiration. Here, the original soil carbon and temperature model of Luke & Cox is augmented with a non-monotone microbial respiration function, for a more realistic representation of the process. This gives rise to a meta-stable state, reproducing the results of [Khvorostyanov et al, Tellus (2008), 60B] where a complex PDE model is used. Two non-autonomous climate forcings are examined: (i) a rise in mean air temperature over decades (ii) a short-lived extreme weather event, with the rate-induced compost bomb observed in each. Using techniques of compactification, singular perturbation theory and desingularisation, we reduce the R-tipping problem to one of heteroclinic orbits, uncovering the tipping mechanism for each climate change scenario."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-11-by-ann-smith",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-11-by-ann-smith",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 11 by Ann Smith",
    "text": "Seminar week 11 by Ann Smith\nDate: 2024-04-12 at 12pm\nSpeaker: Ann Smith (NA)\nHost: Kevin Moroney\nTitle: Predictive Maintenance in the Digital Era\nAbstract: In this seminar, “Predictive Maintenance in the Digital Era,” I’ll explore the essentials of modern predictive maintenance. We’ll cover condition monitoring, data acquisition and management, parameter selection strategies, and model potential.\nWe’ll start by dissecting condition monitoring, focusing on managing sensor data from large-scale engineering systems. I’ll discuss effective parameter selection methods, including both manual inspection and genetic algorithms.\nWhile real-time monitoring is valuable, it’s a retrospective methodology and at best give instantaneous information on process conditions so typically stops at detection and diagnosis, lacking in prognosis. However, I’ll highlight the potential for future advancements in this area.\nWe’ll also briefly touch on Functional Principal Component Analysis (FPCA) and its possible role in modeling, as well as the potential of the Sparse Identification of Nonlinear Dynamics (SINDy) algorithm for creating digital twins.\nIf system dynamics can be reliably recovered from data along with insights into the complexities of predictive maintenance this will pave the way for a more reliable future."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-12-by-allan-greenleaf",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-12-by-allan-greenleaf",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 12 by Allan Greenleaf",
    "text": "Seminar week 12 by Allan Greenleaf\nDate: 2024-04-16 at 12pm\nSpeaker: Allan Greenleaf (NA)\nHost: Cliff Nolan\nTitle: Partition Optimization: Multilinear Estimates from Linear Bounds\nAbstract: Multilinear operators arise in a wide range of settings, from pure to applied maths. Estimates for multilinear operators are generally more difficult to obtain than for linear ones. I will discuss a very general `cheap’ method of leveraging known estimates for linear operators to (possibly) get estimates for multilinear ones, and give some examples, focusing on generalized Radon transforms."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-12-by-mel-devine",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-12-by-mel-devine",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 12 by Mel Devine",
    "text": "Seminar week 12 by Mel Devine\nDate: 2024-04-19 at 12pm\nSpeaker: Mel Devine (NA)\nHost: David O’Sullivan\nTitle: Using Complementarity Problems for Game Theory Optimisation: an application for electricity market modelling.\nAbstract: Game theory optimisation involves solving the constrained optimisation problem of several competing players in equilibrium. Numerous mathematical approaches can be used to solve such problems. In this talk, the Complementarity Problem approach will be introduced and discussed. Then, an application to an electricity market model will be presented. In this model, we consider what the optimal investment mix in green technologies (wind energy, solar photovoltaic, and battery storage) will be. The players we model include generating firms, different consumer groups, and a battery storage operator. The uncertainty of wind energy and solar photovoltaic brings stochasticity into the model. We apply the model to a case study of the Irish electricity system in 2030, which is envisaged to have a significant presence of renewable sources. We consider the optimal investment mix when market power (strategic behaviour) is both present and absent from the market. Previous similar work either neglected investment decisions or market power. We observe that the presence of market power increases electricity prices which leads to increased profits for generating firms and higher consumer costs. It also leads to increased investment in green technologies but reduced carbon emissions."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-15-by-natalya-pya-arnqvis",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-15-by-natalya-pya-arnqvis",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 15 by Natalya Pya Arnqvis",
    "text": "Seminar week 15 by Natalya Pya Arnqvis\nDate: 2024-05-09 at 12pm\nSpeaker: Natalya Pya Arnqvis (NA)\nHost: Kevin Burke\nTitle: Extended generalized additive modelling with shape constraints\nAbstract: Regression models that incorporate smooth functions of predictor variables to explain the relationships with a response variable have gained widespread usage and proved successful in various applications. By incorporating smooth functions of predictor variables, these models can capture complex relationships between the response and predictors while still allowing for interpretation of the results. In situations where the relationships between a response variable and predictors are explored, it is not uncommon to assume that these relationships adhere to certain shape constraints. Examples of such constraints include monotonicity and convexity. Shape-constrained additive models (SCAM) offer a general framework for fitting exponential family generalized additive models with shape restrictions on smooths. The main objective of this talk is to provide extensions of the existing framework for SCAM with a mixture of unconstrained terms and various shape-restricted terms to accommodate smooth interaction of covariates, varying coefficient terms, linear functionals with or without shape constraints as model components, and data with short-term temporal or spatial autocorrelation. The practical usage of the suggested extensions will be illustrated in several examples."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-16-by-graeme-hocking",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-16-by-graeme-hocking",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 16 by Graeme Hocking",
    "text": "Seminar week 16 by Graeme Hocking\nDate: 2024-07-01 at 12pm\nSpeaker: Graeme Hocking (NA)\nHost: James Gleeson\nTitle: Splashes, waves and bores - unsteady, free-surface flows\nAbstract: Superficially it should be relatively simple to simulate the movement of an air-water interface, but the development of curvature singularities places strict limits how far one can go. However, a “fundamental singularities” method does not seem to have this problem and simulations can run until the surface breaks up in some way due to splashing or wave breaking. The availability of such simulations allows us to consider the behaviour of a number of flows. Surface evolution due to flow from sources and into sinks will produce a number of interesting surface effects as described in the title."
  },
  {
    "objectID": "create_AY23-24_sem_2_timetable.html#seminar-week-19-by-laura-keane",
    "href": "create_AY23-24_sem_2_timetable.html#seminar-week-19-by-laura-keane",
    "title": "AY 2023-2024 Semester 2 Seminar Schedule",
    "section": "Seminar week 19 by Laura Keane",
    "text": "Seminar week 19 by Laura Keane\nDate: 2024-08-01 at 12pm\nSpeaker: Laura Keane (NA)\nHost: Doireann O’Kiely\nTitle: Simulation and analysis of double charge layers in electrolyte models for Lithium-ion batteries\nAbstract: Rechargeable batteries such as Lithium-ion batteries (LIBs) are becoming widespread in our society as a means of powering devices. Mathematical modelling can be a valuable tool for gaining insight into observed behaviours and in aiding battery testing as we increase our dependence on these LIBs. Double charge layers are narrow boundary regions between the two main components of a battery: the electrode and the electrolyte. The behaviour in these regions can differ from that observed in the bulk due to the reactions occurring and the transfer of ions at the interfaces. Historically, there has been considerably more investigation and modelling regarding liquid electrolytes and their double charge layers in comparison with the less established solid electrolyte. Solid state electrolytes are becomingly increasingly attractive due to their improved safety, lower self-discharge, and higher power densities over the more commonly used liquid electrolyte. We use mathematical modelling techniques such as numerical simulation and asymptotic analysis to gain a deeper understanding of what is happening in these layers, with a particular emphasis on solid electrolytes and elucidating the differences between liquid and solid electrolyte double charge layers. We consider a model for a solid electrolyte derived under thermodynamics principles in zero charge flux equilibrium and isothermal conditions. We use an auxiliary variable to transform from a finite domain to an infinite domain to avoid numerical artifacts of near singularities and to facilitate robust numerical simulations. We use asymptotic techniques to characterize the true width of the boundary layer of the electrolyte. We find that the asymptotic matching between the different regions is non-standard, and we therefore implement a pseudo matching technique to complete our asymptotic solution. From the asymptotics, we identify both strong and weak space charge layers (SCL). The weak SCL layer is characterised by a length which is equivalent to the Debye length of a standard liquid electrolyte. The strong SCL layer is characterised by a scaled Debye length. We identify these length scales formally from the asymptotic reduction of the model allowing a quantifiable measure of SCL widths."
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-1-by-nastaran-sharifian",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-1-by-nastaran-sharifian",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 1 by Nastaran Sharifian",
    "text": "Seminar week 1 by Nastaran Sharifian\nDate: 2024-09-13 at 2pm\nSpeaker: Nastaran Sharifian (Galway University)\nHost: Kevin Burke\nTitle: Automating functional data analysis in real time: an application to pressure sensor data in the treatment of venous leg ulcers\nAbstract: Venous Leg Ulcers (VLUs) afflict approximately 11.5 million individuals globally, stemming from impaired leg vein function. Compression therapy is the conventional treatment for VLUs, but ensuring appropriate pressure remains a challenge. The novel medical device, Tight Alright developed by FeelTect, can measure bandage pressure 20 times per second at three relevant physiological points on the leg, ensuring effective venous return along the length of the leg and promoting VLU healing. The Tight Alright connected health platform provides measurement of sub-bandage pressure when applying compression therapy, ensuring safe and efficacious target pressure is consistently delivered. These pressure data are transmitted wirelessly (via Bluetooth) to a user-friendly Mobile App, leading to multivariate real-time sensor data. Pressure data are available from the same individual using the pressure sensing device and app under two pressure settings while performing three exercises for 60 seconds each.\nLeveraging Functional Data Analysis (FDA), we smoothed these data to derive a finite-dimensional representation for model fitting, facilitating Multivariate Functional Principal Component Analysis (MFPCA). MFPCA, akin to traditional Principal Component Analysis (PCA) but tailored for multivariate functional data, decomposes variability into orthogonal functional principal components (FPCs), enabling dimension reduction and visualisation. Each pressure wave is attributed a multivariate score for each component of variation, and these scores are then modelled using longitudinal data analysis to investigate pressure change over time and compare between exercise states.\nWe develop an algorithm to automate pressure wave detection, segmentation, registration, and MFPCA, culminating in multivariate principal component scores. These scores compute variation across the three sensor positions for each wave. We use longitudinal data analysis to model these scores over time to find differences between exercise and starting pressure.\nThis approach accommodates the influx of pressure sensor data, ensuring adaptability to new datasets and facilitating real-time analysis for individuals utilising the monitoring device so as to harness and harmonise these multimodal data into useful user facing visualisations on the app. This will ultimately advance monitoring and treatment decision making in VLU wound treatment, which will advance the use of connected-health technology with precision compression therapy to expedite wound healing.\nKeywords: Venous Leg Ulcers, Compression Therapy, Pressure Sensor Data, Multivariate Functional Principal Component Analysis"
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-2-by-laurent-hébert-dufresne",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-2-by-laurent-hébert-dufresne",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 2 by Laurent Hébert-Dufresne",
    "text": "Seminar week 2 by Laurent Hébert-Dufresne\nDate: 2024-09-20 at 2pm\nSpeaker: Laurent Hébert-Dufresne (University of Vermont)\nHost: James Gleeson\nTitle: Contagion models that challenge the linear relationship between exposure and transmission\nAbstract: Models of contagions attempt to reduce complex global dynamics (like a pandemic) to a set of simple local interactions (pairwise transmissions). To do so, it is common to assume that the force of infection on a susceptible individual is linearly proportional to its exposure to the contagion. Here, I will tell two stories of models that implicitly challenge this assumption by acknowledging that the context of exposure matters. First, we will look at heterogeneous patterns of transmission occurring when infection risk varies by orders of magnitude in different settings, like indoor versus outdoor gatherings in the COVID-19 pandemic. Second, we will stop assuming that epidemics happen in a vacuum and consider interactions through co-infections, like COVID-19 and influenza. Spoiler alert: Both stories will show an induced superlinear force of infection during the emergence of a new outbreak when we are unaware of the full context of the exposure and transmission events. These results potentially have important consequences in a wide range of modelling scenarios as they illustrate that superlinear dynamics can emerge from unobserved covariates even when the dynamics is otherwise linear."
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-3-by-graham-benham",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-3-by-graham-benham",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 3 by Graham Benham",
    "text": "Seminar week 3 by Graham Benham\nDate: 2024-09-27 at 2pm\nSpeaker: Graham Benham (University College Dublin)\nHost: Doireann O’Kiely\nTitle: Wave-driven propulsion\nAbstract: Wave-driven propulsion occurs when a floating body, driven into oscillations at the fluid interface, is propelled by the waves generated by its own motion. Wave-driven propulsion has been observed in the case of the waves generated by a honeybee trapped on the surface of water, in the case of “SurferBot”, a centimeter-scale interfacial robot that was inspired by the stricken honeybee, and at much larger scales, in the case of the waves generated by jumping up and down on a canoe, also known as “gunwale bobbing”.\nIn this seminar I will present a new theory for wave-driven propulsion based on coupling the equations of motion of a floating raft to a quasi-potential flow model of the fluid. Using this model, expressions are derived for the drift speed and propulsive thrust of the raft which in turn are shown to be consistent with global momentum conservation. The validity of the model is explored by describing the motion of SurferBot, demonstrating close agreement with the experimentally determined drift speed and oscillatory dynamics. The efficiency of wave-driven propulsion is then computed as a function of driving oscillation frequency and the forcing location, revealing optimal values for both of these parameters which await confirmation in experiments."
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-5-by-vincent-labatut",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-5-by-vincent-labatut",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 5 by Vincent Labatut",
    "text": "Seminar week 5 by Vincent Labatut\nDate: 2024-10-11 at 2pm\nSpeaker: Vincent Labatut (UL)\nHost: Padraig.MacCarron\nTitle: Continuous Average Straightness in Spatial Graphs\nAbstract: The Straightness is a measure designed to characterize a pair of vertices in a spatial graph. In practice, it is often averaged over the whole graph, or a part of it. The standard approach consists in: 1) discretizing the graph edges; 2) processing the vertex-to-vertex Straightness considering the additional vertices resulting from this discretization; and 3) averaging the obtained values. However, this discrete approximation can be computationally expensive on large graphs, and its precision has not been clearly assessed. In this work, we adopt a continuous approach to average the Straightness over the edges of spatial graphs. This allows us to derive 5 distinct measures able to characterize precisely the accessibility of the whole graph, as well as individual vertices and edges. Our method is generic and could be applied to other measures designed for spatial graphs. We perform an experimental evaluation of our continuous average Straightness measures, and show how they behave differently from the traditional vertex-to-vertex ones. Moreover, we also study their discrete approximations, and show that our approach is globally less demanding in terms of both processing time and memory usage."
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-6-by-lennon-ó-náraigh",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-6-by-lennon-ó-náraigh",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 6 by Lennon Ó Náraigh",
    "text": "Seminar week 6 by Lennon Ó Náraigh\nDate: 2024-10-18 at 2pm\nSpeaker: Lennon Ó Náraigh (University College Dublin)\nHost: Eugene Benilov\nTitle: A mathematical model and mesh-free numerical method for contact-line motion in lubrication theory\nAbstract: In gas-liquid flows, a contact line refers to the intersection between the gas-liquid interface and a boundary wall. If the fluid is in motion, then so is the contact line. This apparently contradicts the no-slip boundary condition of fluid dynamics, and gives rise to a singularity in the equations of motion. Such a paradox signals missing physics. A problem is that the missing physics is on the nanoscale, whereas the typical fluid dynamical applications are on the micron or millimeter scales. It becomes necessary in practice to parametrize the missing physics. In this talk, we give an overview of two classical parametrizations which are extremely useful for two-phase flow simulations. This part of the talk will be more of a review of the state-of-the-art. Then, we will introduce a novel regularization of the contact-line singularity problem, valid in the case of thin-film flows."
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-8-by-tim-myers",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-8-by-tim-myers",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 8 by Tim Myers",
    "text": "Seminar week 8 by Tim Myers\nDate: 2024-10-31 at 2pm\nSpeaker: Tim Myers (Centre de Recerca Matemàtica, Barcelona)\nHost: James Gleeson\nTitle: Mathematical modelling of the adsorption of environmental contaminants\nAbstract: It is well-documented that it is now virtually impossible to reach internationally agreed-upon energy and climate goals without active removal of environmental contaminants, combined with substantial emission reductions across all sectors. Whilst the solution can only come through a number of technologies, one of the most common and versatile methods for the capture of contaminants from a fluid is via column adsorption. Adsorption columns are employed in the removal of greenhouse gases, volatile organic compounds, emerging contaminants and PFAs, also in water treatment, biogas cleansing and the purification of biopharmaceutical products. They are relatively easy to introduce into an industrial chain and may be applied to both liquids and gases. Consequently, they are a key tool for environmental remediation. In this talk I will discuss recent work of the Environmental Mathematics group in Barcelona. The EM group specialises in the development and analysis of mathematical models of physical processes related to environmental issues. Mathematical solutions are particularly important since they provide explicit relations for system parameters and so lead to an understanding of the physical process not possible through purely numerical studies. After giving a brief overview of our work I will focus on our current main project, the model development and analysis of a variety of column adsorption processes. The basic mathematical model of an adsorption column involves a coupled system of an advection-diffusion equation, describing the evolution of the contaminant concentration as it passes through the column, and a kinetic equation to account for the reaction process where contaminant attaches to an adsorbent material within the column. I will demonstrate how simple mathematical techniques can lead to solutions which accurately match experimental data. Along the way I will demonstrate how previous, long-accepted solutions contain errors and can be highly inaccurate, hopefully proving the power of applied mathematics!"
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-9-by-jochen-einbeck",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-9-by-jochen-einbeck",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 9 by Jochen Einbeck",
    "text": "Seminar week 9 by Jochen Einbeck\nDate: 2024-11-08 at 2pm\nSpeaker: Jochen Einbeck (Durham Univerity)\nHost: Shirin Moghaddam\nTitle: Statistical modelling in radiation biodosimetry\nAbstract: Biological dosimetry, or short biodosimetry, refers to the task of inferring levels of radiation exposure from a retrospectively taken, potentially exposed, blood sample. When exposure to ionizing radiation occurs, this may lead to double-strand breaks which will in turn activate certain DNA-repair response mechanisms. Both the damage itself, and the ensuing repair, deliver a range of biomarkers which can be exploited in order to quantify the contracted dose. This includes dicentric chromosomes, translocations in chromosomes, micronuclei, and `foci’ from certain proteins including gamma-H2AX. These biomarkers have a simple property in common – they are all count data. As such, for the fitting of calibration curves from (designed) laboratory experiments, typical modelling choices are Poisson or multi-parameter generalized linear models for count data. However, the generation of these radiation-induced counts is subject to a variety of complex biological and physical processes, leading to phenomena such as overdispersion and zero-inflation, also sometimes requiring modelling decisions which may be deemed unusual by Statisticians. In this talk I will give an overview of the state of the art of statistical modelling in biological dosimetry, including own work especially in the context of dose estimation for the gamma-H2AX assay, and hopefully make the case that statistical dosimetry is an interesting field for Statisticians to engage with!"
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-10-by-susana-gomes",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-10-by-susana-gomes",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 10 by Susana Gomes",
    "text": "Seminar week 10 by Susana Gomes\nDate: 2024-11-15 at 2pm\nSpeaker: Susana Gomes (University of Warwick)\nHost: Doireann O’Kiely\nTitle: Control of falling liquid films using a hierarchical model approach\nAbstract: The flow of a thin film down an inclined plane is a canonical setup in fluid mechanics and associated technologies, with applications such as coating, where the liquid-gas interface should ideally be flat, and heat or mass transfer, where an increase of interfacial area is desirable. In each of these applications, we would like to robustly and efficiently manipulate the flow in order to drive the dynamics to a desired interfacial shape. In this talk, I will describe a control methodology based on same fluid blowing and suction through the wall. The controls will be developed using simplified models for a falling liquid film based on reduced-order modelling and asymptotic analysis. The goal is to develop control strategies at more cost-effective levels of the hierarchy and investigate their ability to translate across the hierarchy into real-life situations by using direct numerical simulations of the Navier-Stokes equations, which in this context act as an in silico experimental framework. I will discuss distributed controls as well as (more realistic) point-actuated controls, their robustness to parameter uncertainties and validity across the hierarchy of models. If there is time, I will also discuss recent work using optimal control of similar problems"
  },
  {
    "objectID": "create_AY24-25_sem_1_timetable.html#seminar-week-12-by-edouard-bonneville-online",
    "href": "create_AY24-25_sem_1_timetable.html#seminar-week-12-by-edouard-bonneville-online",
    "title": "AY 2024-2025 Semester 1 Seminar Schedule",
    "section": "Seminar week 12 by Edouard Bonneville-Online",
    "text": "Seminar week 12 by Edouard Bonneville-Online\nDate: 2024-11-29 at 2pm\nSpeaker: Edouard Bonneville-Online (Leiden University Medical Centre)\nHost: Shirin Moghaddam\nTitle: Competing risks and multiple imputation of missing covariates\nAbstract: When using multiple imputation (MI) to deal with missing covariates, a central consideration is that the imputation model and substantive model be compatible with each other (i.e. that they do not make conflicting assumptions). In the context of proportional hazards models in competing risks settings, a directly specified imputation model is generally only approximately compatible with the substantive model. In this talk, I will introduce various MI approaches for both cause-specific Cox models and the Fine-Gray model, and discuss how they perform based on simulation studies. I will also briefly touch upon how the development of a substantive model compatible imputation approach when using the Fine-Gray model provides insights into broader model misspecification issues in competing risks settings."
  },
  {
    "objectID": "create_AY25-26_sem_2_timetable.html",
    "href": "create_AY25-26_sem_2_timetable.html",
    "title": "AY 2025-2026 Semester 2 Seminar Schedule",
    "section": "",
    "text": "Timetable\n\n\nDateTimeWeek no.PresenterAffil.Dept. ContactTitle2026-01-2911am1OpenTBCTBCTBC2026-02-1211am3OpenTBCTBCTBC2026-02-2611am5OpenTBCTBCTBC2026-03-1211am7OpenTBCTBCTBC2026-03-2611am9OpenTBCTBCTBC2026-04-0911am11OpenTBCTBCTBC2026-04-2311am13OpenTBCTBCTBC"
  }
]